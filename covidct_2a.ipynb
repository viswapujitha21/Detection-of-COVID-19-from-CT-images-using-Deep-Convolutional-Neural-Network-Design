{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "covidct-2a.ipynb",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# importing necessary libraries\n",
        "import os\n",
        "import time\n",
        "import copy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch,torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import datasets, models, transforms\n",
        "import torch.optim as optim\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import resample\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from torch.nn import Parameter"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-25T15:56:18.467872Z",
          "iopub.execute_input": "2022-04-25T15:56:18.468287Z",
          "iopub.status.idle": "2022-04-25T15:56:20.647988Z",
          "shell.execute_reply.started": "2022-04-25T15:56:18.468202Z",
          "shell.execute_reply": "2022-04-25T15:56:20.647184Z"
        },
        "trusted": true,
        "id": "OtCoT4Wx01fK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections.abc import Iterable\n",
        "\n",
        "def set_freeze_by_idxs(model, idxs, freeze=True): \n",
        "    \"\"\" Function to freeze layers of model during fine-training\"\"\"\n",
        "    if not isinstance(idxs, Iterable):\n",
        "        idxs = [idxs]\n",
        "    num_child = len(list(model.children()))\n",
        "    idxs = tuple(map(lambda idx: num_child + idx if idx < 0 else idx, idxs))\n",
        "    for idx, child in enumerate(model.children()):\n",
        "        if idx not in idxs:\n",
        "            continue\n",
        "        for param in child.parameters():\n",
        "            param.requires_grad = not freeze\n",
        "    return model\n",
        "            \n",
        "def freeze_by_idxs(model, idxs):\n",
        "    return set_freeze_by_idxs(model, idxs, True)\n",
        "\n",
        "def unfreeze_by_idxs(model, idxs):\n",
        "    return set_freeze_by_idxs(model, idxs, False)\n",
        "\n",
        "def set_parameter_requires_grad(model):\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad=False\n",
        "    return model\n",
        "\n",
        "def initialize_model(model_name, num_classes, use_pretrained, unfreeze_num):\n",
        "    \"\"\"Function to intialize various model ['vgg16','vgg19','resnet101','resnet152','densenet161','densenet201']\n",
        "        and modify their layers accordingly.\n",
        "    \"\"\"\n",
        "    if model_name=='vgg16':\n",
        "        model_pre=models.vgg16(pretrained=use_pretrained) \n",
        "\n",
        "        model_pre.features[0].in_channels=1\n",
        "        model_pre.features[0].weight=Parameter(model_pre.features[0].weight[:,1:2,:,:])\n",
        "        model_pre=set_parameter_requires_grad(model_pre) \n",
        "        num_ftrs=model_pre.classifier[6].in_features # feature_map \n",
        "        model_pre.classifier[6]=nn.Linear(num_ftrs,num_classes) \n",
        "        if unfreeze_num==1:\n",
        "            unfreeze=[-1]\n",
        "        elif unfreeze_num==2:\n",
        "            unfreeze=[-1,-3]\n",
        "        elif unfreeze_num==3:\n",
        "            unfreeze=[-1,-3,-5]\n",
        "        else:\n",
        "            unfreeze=[-1,-3,-5,-7]\n",
        "        model_pre.features=unfreeze_by_idxs(model_pre.features,unfreeze)\n",
        "        for param in model_pre.classifier.parameters():\n",
        "            param.requires_grad=True\n",
        "        input_size=224\n",
        "    elif model_name=='vgg19':\n",
        "        model_pre=models.vgg19(pretrained=use_pretrained) \n",
        "        model_pre.features[0].in_channels=1\n",
        "        model_pre.features[0].weight=Parameter(model_pre.features[0].weight[:,1:2,:,:])\n",
        "        model_pre=set_parameter_requires_grad(model_pre) \n",
        "        num_ftrs=model_pre.classifier[6].in_features\n",
        "        model_pre.classifier[6]=nn.Linear(num_ftrs,num_classes) \n",
        "        if unfreeze_num==1:\n",
        "            unfreeze=[-1]\n",
        "        elif unfreeze_num==2:\n",
        "            unfreeze=[-1,-3]\n",
        "        elif unfreeze_num==3:\n",
        "            unfreeze=[-1,-3,-5]\n",
        "        else:\n",
        "            unfreeze=[-1,-3,-5,-7]\n",
        "        model_pre.features=unfreeze_by_idxs(model_pre.features,unfreeze)\n",
        "        for param in model_pre.classifier.parameters():\n",
        "            param.requires_grad=True\n",
        "        input_size=224\n",
        "    elif model_name=='resnet101':\n",
        "        model_pre=models.resnet101(pretrained=use_pretrained) \n",
        "        model_pre.conv1.in_channels=1\n",
        "        model_pre.conv1.weight=Parameter(model_pre.conv1.weight[:,1:2,:,:])\n",
        "        model_pre=set_parameter_requires_grad(model_pre)\n",
        "        num_ftrs=model_pre.fc.in_features \n",
        "        model_pre.fc=nn.Linear(num_ftrs,num_classes)\n",
        "        \n",
        "        for i in range(unfreeze_num):\n",
        "            model_pre.layer4=unfreeze_by_idxs(model_pre.layer4,-i)\n",
        "        for param in model_pre.fc.parameters():\n",
        "            param.requires_grad=True\n",
        "        input_size=224\n",
        "    elif model_name=='resnet152':\n",
        "        model_pre=models.resnet152(pretrained=use_pretrained) \n",
        "        model_pre.conv1.in_channels=1\n",
        "        model_pre.conv1.weight=Parameter(model_pre.conv1.weight[:,1:2,:,:])\n",
        "        model_pre=set_parameter_requires_grad(model_pre)\n",
        "        num_ftrs=model_pre.fc.in_features\n",
        "        model_pre.fc=nn.Linear(num_ftrs,num_classes)\n",
        "\n",
        "        for i in range(unfreeze_num):\n",
        "            model_pre.layer4=unfreeze_by_idxs(model_pre.layer4,-i)\n",
        "        for param in model_pre.fc.parameters():\n",
        "            param.requires_grad=True\n",
        "        input_size=224\n",
        "    elif model_name=='densenet161':\n",
        "        model_pre=models.densenet161(pretrained=use_pretrained)\n",
        "        model_pre.features[0].in_channels=1\n",
        "        model_pre.features[0].weight=Parameter(model_pre.features[0].weight[:,1:2,:,:])\n",
        "        model_pre=set_parameter_requires_grad(model_pre)\n",
        "        num_ftrs=model_pre.classifier.in_features \n",
        "        model_pre.classifier=nn.Linear(num_ftrs,num_classes)\n",
        "        \n",
        "        for i in range(unfreeze_num):\n",
        "            model_pre.features.denseblock4=unfreeze_by_idxs(model_pre.features.denseblock4,-i)\n",
        "        for param in model_pre.classifier.parameters():\n",
        "            param.requires_grad=True\n",
        "        input_size=224\n",
        "    elif model_name=='densenet201':\n",
        "        model_pre=models.densenet201(pretrained=use_pretrained)\n",
        "        model_pre.features[0].in_channels=1\n",
        "        model_pre.features[0].weight=Parameter(model_pre.features[0].weight[:,1:2,:,:])\n",
        "        model_pre=set_parameter_requires_grad(model_pre)\n",
        "        num_ftrs=model_pre.classifier.in_features \n",
        "        model_pre.classifier=nn.Linear(num_ftrs,num_classes)\n",
        "        \n",
        "        for i in range(unfreeze_num):\n",
        "            model_pre.features.denseblock4=unfreeze_by_idxs(model_pre.features.denseblock4,-i)\n",
        "        for param in model_pre.classifier.parameters():\n",
        "            param.requires_grad=True\n",
        "        input_size=224\n",
        "    else:\n",
        "        print('model not implemented')\n",
        "        return None,None\n",
        "    return model_pre, input_size"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-25T15:56:23.730153Z",
          "iopub.execute_input": "2022-04-25T15:56:23.730709Z",
          "iopub.status.idle": "2022-04-25T15:56:23.763486Z",
          "shell.execute_reply.started": "2022-04-25T15:56:23.730646Z",
          "shell.execute_reply": "2022-04-25T15:56:23.762152Z"
        },
        "trusted": true,
        "id": "ZzVbM-Dr01fM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "model_all = []\n",
        "dir = '.'\n",
        "\n",
        "def auto_net(model_name, num_classes, use_pretrained, unfreeze_num):\n",
        "    model_all = []\n",
        "    for k in range(unfreeze_num):\n",
        "        model, input_size = initialize_model(model_name, num_classes, use_pretrained, k+1)\n",
        "        my_path = Path(dir + '/{}'.format(model_name))\n",
        "        if not my_path.is_dir():    \n",
        "            os.mkdir(my_path)\n",
        "        torch.save(model, dir + '/{}/{}_{}.pth'.format(model_name, model_name, k)) \n",
        "        model_all.append(model)\n",
        "    return model_all\n",
        "\n",
        "model_name = ['vgg16','vgg19','resnet101','resnet152','densenet161','densenet201'] \n",
        "\n",
        "# using densenet161 as our model\n",
        "# can experiment with other models\n",
        "model_all = auto_net(model_name[4], num_classes=3, use_pretrained=False, unfreeze_num=4)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-25T16:10:02.422870Z",
          "iopub.execute_input": "2022-04-25T16:10:02.423253Z",
          "iopub.status.idle": "2022-04-25T16:10:28.734777Z",
          "shell.execute_reply.started": "2022-04-25T16:10:02.423218Z",
          "shell.execute_reply": "2022-04-25T16:10:28.733018Z"
        },
        "trusted": true,
        "id": "7LjE7r6L01fN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Preparation\n",
        "# Training dataframe\n",
        "train_df = pd.read_csv('../input/covidxct/train_COVIDx_CT-2A.txt', sep=\" \", header=None)\n",
        "train_df.columns=['filename', 'label', 'xmin','ymin','xmax','ymax']\n",
        "train_df=train_df.drop(['xmin', 'ymin','xmax', 'ymax'], axis=1 )\n",
        "\n",
        "# Validation dataframe\n",
        "val_df = pd.read_csv('../input/covidxct/val_COVIDx_CT-2A.txt', sep=\" \", header=None)\n",
        "val_df.columns=['filename', 'label', 'xmin','ymin','xmax','ymax']\n",
        "val_df=val_df.drop(['xmin', 'ymin','xmax', 'ymax'], axis=1 )\n",
        "\n",
        "# Testing dataframe\n",
        "test_df = pd.read_csv('../input/covidxct/test_COVIDx_CT-2A.txt', sep=\" \", header=None)\n",
        "test_df.columns=['filename', 'label', 'xmin','ymin','xmax','ymax']\n",
        "test_df=test_df.drop(['xmin', 'ymin','xmax', 'ymax'], axis=1 )"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-25T16:03:18.981002Z",
          "iopub.execute_input": "2022-04-25T16:03:18.981670Z",
          "iopub.status.idle": "2022-04-25T16:03:19.434676Z",
          "shell.execute_reply.started": "2022-04-25T16:03:18.981603Z",
          "shell.execute_reply": "2022-04-25T16:03:19.433777Z"
        },
        "trusted": true,
        "id": "Ry72hcJO01fO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.label.value_counts()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-25T16:03:31.023058Z",
          "iopub.execute_input": "2022-04-25T16:03:31.023431Z",
          "iopub.status.idle": "2022-04-25T16:03:31.040663Z",
          "shell.execute_reply.started": "2022-04-25T16:03:31.023400Z",
          "shell.execute_reply": "2022-04-25T16:03:31.039596Z"
        },
        "trusted": true,
        "id": "muXgC_9x01fO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = '../input/covidxct/2A_images/'  # directory path of images\n",
        "train_df['filename'] = image_path + train_df['filename']\n",
        "val_df['filename'] = image_path + val_df['filename']\n",
        "test_df['filename'] = image_path + test_df['filename']\n",
        "\n",
        "train_df.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-25T16:03:32.777524Z",
          "iopub.execute_input": "2022-04-25T16:03:32.777917Z",
          "iopub.status.idle": "2022-04-25T16:03:32.855186Z",
          "shell.execute_reply.started": "2022-04-25T16:03:32.777879Z",
          "shell.execute_reply": "2022-04-25T16:03:32.854083Z"
        },
        "trusted": true,
        "id": "4fQTDYQ-01fO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Balancing the training and validation datastets"
      ],
      "metadata": {
        "id": "mJk7SOyV01fO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N = train_df[train_df['label'] == 0]\n",
        "P = train_df[train_df['label'] == 1]\n",
        "C = train_df[train_df['label'] == 2]\n",
        "\n",
        "from sklearn.utils import resample\n",
        "\n",
        "N_download = resample(N, replace = True, n_samples = 25496, random_state=0)\n",
        "C_download = resample(C, replace = True, n_samples = 25496, random_state=0)\n",
        "train_df = pd.concat([N_download, P, C_download])\n",
        "train_df.label.value_counts()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-25T16:03:42.124329Z",
          "iopub.execute_input": "2022-04-25T16:03:42.124960Z",
          "iopub.status.idle": "2022-04-25T16:03:42.162766Z",
          "shell.execute_reply.started": "2022-04-25T16:03:42.124905Z",
          "shell.execute_reply": "2022-04-25T16:03:42.161579Z"
        },
        "trusted": true,
        "id": "l32J_TeD01fP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_v = val_df[val_df['label'] == 0]\n",
        "P_v = val_df[val_df['label'] == 1]\n",
        "C_v = val_df[val_df['label'] == 2]\n",
        "\n",
        "from sklearn.utils import resample\n",
        "\n",
        "N_v_download = resample(N_v, replace = True, n_samples = 6244,random_state=0)\n",
        "P_v_download = resample(P_v, replace = True, n_samples = 6244,random_state=0)\n",
        "val_df = pd.concat([N_v_download, P_v_download, C_v])\n",
        "\n",
        "val_df.label.value_counts()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-25T16:03:44.919100Z",
          "iopub.execute_input": "2022-04-25T16:03:44.919829Z",
          "iopub.status.idle": "2022-04-25T16:03:44.943061Z",
          "shell.execute_reply.started": "2022-04-25T16:03:44.919779Z",
          "shell.execute_reply": "2022-04-25T16:03:44.942072Z"
        },
        "trusted": true,
        "id": "wBPfdEeD01fP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = shuffle(train_df) \n",
        "val_df = shuffle(val_df)\n",
        "test_df = shuffle(test_df)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-25T16:03:49.244668Z",
          "iopub.execute_input": "2022-04-25T16:03:49.245019Z",
          "iopub.status.idle": "2022-04-25T16:03:49.266220Z",
          "shell.execute_reply.started": "2022-04-25T16:03:49.244990Z",
          "shell.execute_reply": "2022-04-25T16:03:49.265098Z"
        },
        "trusted": true,
        "id": "c-ZORs0B01fQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = {0:'Normal',1:'Pneumonia',2:'COVID-19'}\n",
        "class_names = ['Normal','Pneumonia','COVID-19']\n",
        "\n",
        "train_df['label_n'] = [labels[b] for b in train_df['label']]\n",
        "val_df['label_n'] = [labels[b] for b in val_df['label']]\n",
        "test_df['label_n'] = [labels[b] for b in test_df['label']]\n",
        "train_df.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-25T16:03:53.662662Z",
          "iopub.execute_input": "2022-04-25T16:03:53.663058Z",
          "iopub.status.idle": "2022-04-25T16:03:53.714986Z",
          "shell.execute_reply.started": "2022-04-25T16:03:53.663021Z",
          "shell.execute_reply": "2022-04-25T16:03:53.713952Z"
        },
        "trusted": true,
        "id": "_gDcIgwG01fQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Negative and positive values of train: \\n{train_df['label_n'].value_counts()}\")\n",
        "print(f\"Negative and positive values of validation: \\n{val_df['label_n'].value_counts()}\")\n",
        "print(f\"Negative and positive values of test: \\n{test_df['label_n'].value_counts()}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-25T16:03:58.033758Z",
          "iopub.execute_input": "2022-04-25T16:03:58.034116Z",
          "iopub.status.idle": "2022-04-25T16:03:58.072695Z",
          "shell.execute_reply.started": "2022-04-25T16:03:58.034085Z",
          "shell.execute_reply": "2022-04-25T16:03:58.071460Z"
        },
        "trusted": true,
        "id": "vXaYjE3y01fQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df=train_df.reset_index()\n",
        "val_df=val_df.reset_index()\n",
        "test_df=test_df.reset_index()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-25T16:04:04.083514Z",
          "iopub.execute_input": "2022-04-25T16:04:04.083919Z",
          "iopub.status.idle": "2022-04-25T16:04:04.095523Z",
          "shell.execute_reply.started": "2022-04-25T16:04:04.083884Z",
          "shell.execute_reply": "2022-04-25T16:04:04.094377Z"
        },
        "trusted": true,
        "id": "BY_bcSe801fQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CovidDataset(Dataset):\n",
        "    def __init__(self, dataset_df, transform=None):\n",
        "        self.dataset_df = dataset_df\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.dataset_df.shape[0]\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        image_name = self.dataset_df['filename'][idx]\n",
        "        img = Image.open(image_name)\n",
        "        label = self.dataset_df['label'][idx]\n",
        "        \n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, label"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-25T16:04:07.731616Z",
          "iopub.execute_input": "2022-04-25T16:04:07.732465Z",
          "iopub.status.idle": "2022-04-25T16:04:07.740051Z",
          "shell.execute_reply.started": "2022-04-25T16:04:07.732409Z",
          "shell.execute_reply": "2022-04-25T16:04:07.739087Z"
        },
        "trusted": true,
        "id": "_wAWldHv01fQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training variables\n",
        "batch_size = 64\n",
        "input_channel = 1\n",
        "input_size = (224,224)\n",
        "crop_size = (340,380)\n",
        "num_classes =3\n",
        "num_epochs = 20"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-25T16:04:14.063382Z",
          "iopub.execute_input": "2022-04-25T16:04:14.063790Z",
          "iopub.status.idle": "2022-04-25T16:04:14.068913Z",
          "shell.execute_reply.started": "2022-04-25T16:04:14.063753Z",
          "shell.execute_reply": "2022-04-25T16:04:14.067947Z"
        },
        "trusted": true,
        "id": "cWzvj34I01fR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Image transformations \n",
        "transform = {\n",
        "    'train':transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(p=0.5), # Image augmentations for training\n",
        "        transforms.RandomVerticalFlip(p=0.5),\n",
        "        transforms.RandomRotation(30),\n",
        "        transforms.CenterCrop(crop_size),\n",
        "        transforms.Resize(input_size),\n",
        "        transforms.Grayscale(input_channel),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.6349431],[0.32605055])\n",
        "    ]),\n",
        "    'test':transforms.Compose([\n",
        "        transforms.CenterCrop(crop_size),\n",
        "        transforms.Resize(input_size),\n",
        "        transforms.Grayscale(input_channel),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.63507175],[0.3278614])\n",
        "    ])\n",
        "}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-25T16:04:20.667913Z",
          "iopub.execute_input": "2022-04-25T16:04:20.668665Z",
          "iopub.status.idle": "2022-04-25T16:04:20.677487Z",
          "shell.execute_reply.started": "2022-04-25T16:04:20.668589Z",
          "shell.execute_reply": "2022-04-25T16:04:20.676422Z"
        },
        "trusted": true,
        "id": "KbGmavMY01fR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_names = ['train','val','test']\n",
        "image_transforms = {'train':transform['train'], 'val':transform['test'],'test':transform['test']}\n",
        "\n",
        "train_dataset = CovidDataset(train_df, transform=image_transforms['train'])\n",
        "val_dataset = CovidDataset(val_df, transform=image_transforms['val'])\n",
        "test_dataset = CovidDataset(test_df, transform=image_transforms['test'])\n",
        "\n",
        "image_dataset = {'train':train_dataset, 'val':val_dataset,'test':test_dataset}\n",
        "\n",
        "dataloaders = {x:DataLoader(image_dataset[x],batch_size=batch_size,shuffle=True,num_workers=4) for x in dataset_names}\n",
        "\n",
        "dataset_sizes = {x:len(image_dataset[x]) for x in dataset_names}\n",
        "\n",
        "print(dataset_sizes)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-25T16:04:24.450473Z",
          "iopub.execute_input": "2022-04-25T16:04:24.450902Z",
          "iopub.status.idle": "2022-04-25T16:04:24.459656Z",
          "shell.execute_reply.started": "2022-04-25T16:04:24.450864Z",
          "shell.execute_reply": "2022-04-25T16:04:24.458611Z"
        },
        "trusted": true,
        "id": "TMuqaCRf01fR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "def show_tensor_img(tensor_img):\n",
        "    img=transforms.ToPILImage()(tensor_img)\n",
        "    plt.figure()\n",
        "    plt.imshow(img,plt.cm.gray)\n",
        "    plt.show()\n",
        "\n",
        "# Displaying some sample images from train dataset\n",
        "for i in range(4):\n",
        "    show_tensor_img(train_dataset[i][0])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-25T16:04:32.632227Z",
          "iopub.execute_input": "2022-04-25T16:04:32.632814Z",
          "iopub.status.idle": "2022-04-25T16:04:33.460942Z",
          "shell.execute_reply.started": "2022-04-25T16:04:32.632762Z",
          "shell.execute_reply": "2022-04-25T16:04:33.460191Z"
        },
        "trusted": true,
        "id": "ZAnQur_p01fR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "\n",
        "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    cm=cm.numpy()\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        cm=cm.astype('int')\n",
        "        print('Confusion matrix, without normalization')\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "    fmt = '{:.2f}' if normalize else '{}'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "      plt.text(i, j, fmt.format(cm[i, j]),horizontalalignment=\"center\",color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def confusion_matrix(preds, labels, conf_matrix):\n",
        "    preds = torch.argmax(preds, 1)\n",
        "    for p, t in zip(preds, labels):\n",
        "        conf_matrix[t, p] += 1\n",
        "    return conf_matrix\n",
        "\n",
        "def calculate_all_prediction(conf_matrix):\n",
        "    total_sum = conf_matrix.sum()\n",
        "    correct_sum = (np.diag(conf_matrix)).sum()\n",
        "    prediction = round(100*float(correct_sum)/float(total_sum),2)\n",
        "    return prediction\n",
        " \n",
        "def calculate_label_prediction(conf_matrix,labelidx):\n",
        "    label_total_sum = conf_matrix.sum(axis=0)[labelidx]\n",
        "    label_correct_sum = conf_matrix[labelidx][labelidx]\n",
        "    prediction = 0\n",
        "    if label_total_sum != 0:\n",
        "        prediction = round(100*float(label_correct_sum)/float(label_total_sum),2)\n",
        "    return prediction\n",
        " \n",
        "def calculate_label_recall(conf_matrix,labelidx):\n",
        "    label_total_sum = conf_matrix.sum(axis=1)[labelidx]\n",
        "    label_correct_sum = conf_matrix[labelidx][labelidx]\n",
        "    recall = 0\n",
        "    if label_total_sum != 0:\n",
        "        recall = round(100*float(label_correct_sum)/float(label_total_sum),2)\n",
        "    return recall\n",
        " \n",
        "def calculate_f1(prediction,recall):\n",
        "    if (prediction+recall)==0:\n",
        "        return 0\n",
        "    return round(2*prediction*recall/(prediction+recall),2)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-25T16:04:43.957464Z",
          "iopub.execute_input": "2022-04-25T16:04:43.957895Z",
          "iopub.status.idle": "2022-04-25T16:04:44.109104Z",
          "shell.execute_reply.started": "2022-04-25T16:04:43.957856Z",
          "shell.execute_reply": "2022-04-25T16:04:44.107753Z"
        },
        "trusted": true,
        "id": "dde2r5h-01fR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights_path = '../input/densenet161/densenet161.pth'\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model, input_size = initialize_model(model_name[4] , 3 , False, 5)\n",
        "\n",
        "model = model.load_state_dict(torch.load(weights_path))\n",
        "model = model.to(device)\n",
        "\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam( model.parameters(), lr=0.0001,betas=(0.9, 0.999))"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2022-04-25T16:24:01.898969Z",
          "iopub.execute_input": "2022-04-25T16:24:01.899347Z",
          "iopub.status.idle": "2022-04-25T16:24:02.837156Z",
          "shell.execute_reply.started": "2022-04-25T16:24:01.899311Z",
          "shell.execute_reply": "2022-04-25T16:24:02.828786Z"
        },
        "trusted": true,
        "id": "HRCXbQ2v01fR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model,epoch,num_epochs,criterion,optimizer):\n",
        "    model.train()\n",
        "    print('-' * 100)\n",
        "    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    for idx, (inputs, labels) in enumerate(dataloaders['train']):\n",
        "        inputs,labels=inputs.to(device),labels.to(device)\n",
        "        outputs = model(inputs) \n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        loss = criterion(outputs, labels) \n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if idx % 100 == 99:\n",
        "            print('train iteration:{},loss:{},acc:{}%'.format( idx, loss.item(),torch.sum(preds == labels.data)/batch_size*100))\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "    epoch_loss = running_loss / dataset_sizes['train']\n",
        "    epoch_acc = running_corrects.double() / dataset_sizes['train']\n",
        "    print('train_total Loss: {:.4f} Acc: {:.4f}%'.format( epoch_loss, epoch_acc*100))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-26T11:16:12.330013Z",
          "iopub.execute_input": "2021-06-26T11:16:12.33036Z",
          "iopub.status.idle": "2021-06-26T11:16:12.340334Z",
          "shell.execute_reply.started": "2021-06-26T11:16:12.33032Z",
          "shell.execute_reply": "2021-06-26T11:16:12.339312Z"
        },
        "trusted": true,
        "id": "pQf8UzL701fS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model,epoch,num_epochs,criterion,optimizer,best_acc):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    best_acc=best_acc\n",
        "    best_model_wts=copy.deepcopy(model.state_dict())\n",
        "    conf_matrix = torch.zeros(num_classes, num_classes) \n",
        "    with torch.no_grad():\n",
        "        for idx, (inputs, labels) in enumerate(dataloaders['val']):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "            conf_matrix = confusion_matrix(outputs, labels, conf_matrix) \n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data) \n",
        "\n",
        "        plot_confusion_matrix(conf_matrix, classes=class_names, normalize=False, title='confusion matrix') \n",
        "\n",
        "    epoch_loss = running_loss / dataset_sizes['val'] \n",
        "    epoch_acc = running_corrects.double() / dataset_sizes['val'] \n",
        "    print('val_total Loss: {:.4f} Acc: {:.4f}%'.format( epoch_loss, epoch_acc*100))\n",
        "\n",
        "    all_prediction = calculate_all_prediction(conf_matrix) \n",
        "    print('all_prediction:{}'.format(all_prediction))\n",
        "    label_prediction = [] \n",
        "    label_recall = [] \n",
        "    for i in range(num_classes):\n",
        "        label_prediction.append(calculate_label_prediction(conf_matrix,i))\n",
        "        label_recall.append(calculate_label_recall(conf_matrix,i))\n",
        "\n",
        "    keys=class_names\n",
        "    values=list(range(num_classes))\n",
        "    dictionary = dict(zip(keys, values))\n",
        "    for ei,i in enumerate(dictionary):\n",
        "        print(ei,'\\t',i,'\\t','prediction=',label_prediction[ei],'%,\\trecall=',label_recall[ei],'%,\\tf1=',calculate_f1(label_prediction[ei],label_recall[ei])) # 输出每个类的，精确率，召回率，F1\n",
        "    p = round(np.array(label_prediction).sum()/len(label_prediction),2) \n",
        "    r = round(np.array(label_recall).sum()/len(label_prediction),2) \n",
        "    print('MACRO-averaged:\\nprediction=',p,'%,recall=',r,'%,f1=',calculate_f1(p,r)) \n",
        "\n",
        "#     print(epoch_acc.tpye)\n",
        "#     print(best_acc.type)\n",
        "    if epoch_acc > best_acc:\n",
        "        best_acc=epoch_acc.item()\n",
        "        best_model_wts=copy.deepcopy(model.state_dict())\n",
        "\n",
        "    return best_model_wts,best_acc,epoch_acc.item()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-26T11:16:12.34412Z",
          "iopub.execute_input": "2021-06-26T11:16:12.34441Z",
          "iopub.status.idle": "2021-06-26T11:16:12.358677Z",
          "shell.execute_reply.started": "2021-06-26T11:16:12.344367Z",
          "shell.execute_reply": "2021-06-26T11:16:12.357862Z"
        },
        "trusted": true,
        "id": "NlNwo6N301fS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    acc=[]\n",
        "    for epoch in range(num_epochs):\n",
        "        train(model,epoch,num_epochs,criterion,optimizer)\n",
        "        best_model_wts,best_acc,epoch_acc=test(model,epoch,num_epochs,criterion,optimizer,best_acc)\n",
        "        acc.append(epoch_acc)\n",
        "    print('*' * 100)\n",
        "    print('best_acc:{}'.format(best_acc))\n",
        "    print('*' * 100)\n",
        "    torch.save(best_model_wts, 'densenet201_3_model_best_acc.pth')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-26T11:16:12.360147Z",
          "iopub.execute_input": "2021-06-26T11:16:12.360724Z"
        },
        "trusted": true,
        "id": "gT9YVRkW01fS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(acc)"
      ],
      "metadata": {
        "trusted": true,
        "id": "F7111Rtf01fS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=range(len(acc))\n",
        "y=acc\n",
        "plt.figure()\n",
        "plt.title('densenet201_3_acc_lr=0.0001')\n",
        "plt.plot(x,y)\n",
        "plt.savefig('mini64_lr0.0001_e20_densenet201_3_acc.jpg')\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "dBQFjE5g01fS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}